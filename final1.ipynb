{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPA52KYnj3l884CTuxn2Goq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manish190502/financial-fraud-detection-using-generative-AI/blob/main/final1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4EQD04Zr_0ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten, GRU\n",
        "\n",
        "# Load the dataset (assuming it's stored in a DataFrame called 'data')\n",
        "# Replace this with the actual code to load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/fraudset.xlsx')\n",
        "\n",
        "# Preprocess the data (assuming 'Amount' is a feature column)\n",
        "X = data.drop(columns=['Class'])  # Features\n",
        "y = data['Class']  # Target\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape the data for RNN and GRU models\n",
        "X_train_rnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
        "X_test_rnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "# Define and train RNN model\n",
        "rnn_model = Sequential()\n",
        "rnn_model.add(LSTM(units=64, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])))\n",
        "rnn_model.add(Dense(units=1, activation='sigmoid'))\n",
        "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "rnn_model.fit(X_train_rnn, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adr57CQhGOXK",
        "outputId": "4d9c73fe-84ff-4267-9ed4-576c8e3d9a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 3s 16ms/step - loss: 0.6227 - accuracy: 0.7503\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 0.2949 - accuracy: 0.8928\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.1179 - accuracy: 0.9647\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.0884 - accuracy: 0.9786\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.0744 - accuracy: 0.9823\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0706 - accuracy: 0.9823\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0727 - accuracy: 0.9798\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0641 - accuracy: 0.9836\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0708 - accuracy: 0.9798\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0800 - accuracy: 0.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7952c82b9750>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_predictions = rnn_model.predict(X_test_rnn)\n",
        "mean_prediction = np.mean(rnn_predictions)\n",
        "std_prediction = np.std(rnn_predictions)\n",
        "threshold = mean_prediction + 3 * std_prediction  # Example dynamic threshold\n",
        "\n",
        "# Convert probabilities to binary predictions using the threshold\n",
        "rnn_anomalies_indices = np.where(rnn_predictions > threshold)[0]\n",
        "\n",
        "# Print the indices of anomalies detected by RNN\n",
        "print(\"Anomalies detected by RNN:\", rnn_anomalies_indices)\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold of 0.5\n",
        "rnn_predictions_binary = (rnn_predictions >= 0.5).astype(int)\n",
        "\n",
        "# Compute accuracy\n",
        "rnn_accuracy = accuracy_score(y_test, rnn_predictions_binary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZpRbMv1RR97",
        "outputId": "6fcd9478-9514-48fd-85a0-40596bd9a9e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 5ms/step\n",
            "Anomalies detected by RNN: []\n",
            "RNN Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and train CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(units=1, activation='sigmoid'))\n",
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(X_train_scaled, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Define and train FCNN model\n",
        "fcnn_model = Sequential()\n",
        "fcnn_model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "fcnn_model.add(Dense(64, activation='relu'))\n",
        "fcnn_model.add(Dense(1, activation='sigmoid'))\n",
        "fcnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "fcnn_model.fit(X_train_scaled, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Define and train GRU model\n",
        "gru_model = Sequential()\n",
        "gru_model.add(GRU(units=64, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])))\n",
        "gru_model.add(Dense(units=1, activation='sigmoid'))\n",
        "gru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "gru_model.fit(X_train_rnn, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Make predictions for CNN, FCNN, and GRU\n",
        "cnn_predictions = cnn_model.predict(X_test_scaled)\n",
        "fcnn_predictions = fcnn_model.predict(X_test_scaled)\n",
        "gru_predictions = gru_model.predict(X_test_rnn)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCoapzNJXK4d",
        "outputId": "f9b16c52-31a1-47e4-8121-289d2f16df51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 1s 4ms/step - loss: 0.5674 - accuracy: 0.8499\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.9079\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.9231\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2437 - accuracy: 0.9306\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2061 - accuracy: 0.9407\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1799 - accuracy: 0.9470\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9458\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9521\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9571\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9571\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 1s 2ms/step - loss: 0.3814 - accuracy: 0.8512\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1375 - accuracy: 0.9596\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9748\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9849\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9874\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9912\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9962\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9962\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9987\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9975\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 4s 27ms/step - loss: 0.6724 - accuracy: 0.6847\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.6542 - accuracy: 0.6999\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.4814 - accuracy: 0.7970\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.1515 - accuracy: 0.9407\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0957 - accuracy: 0.9697\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.0901 - accuracy: 0.9672\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.0790 - accuracy: 0.9786\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.0757 - accuracy: 0.9723\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 0.0644 - accuracy: 0.9823\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.0624 - accuracy: 0.9823\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions for CNN\n",
        "cnn_predictions = cnn_model.predict(X_test_scaled)\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold of 0.5\n",
        "cnn_predictions_binary = (cnn_predictions >= 0.5).astype(int)\n",
        "\n",
        "# Print anomalies for CNN\n",
        "cnn_anomalies_indices = y_test[cnn_predictions_binary.flatten() != y_test].index\n",
        "\n",
        "\n",
        "# Compute accuracy for CNN\n",
        "cnn_accuracy = accuracy_score(y_test, cnn_predictions_binary)\n",
        "\n",
        "\n",
        "# Make predictions for FCNN\n",
        "fcnn_predictions = fcnn_model.predict(X_test_scaled)\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold of 0.5\n",
        "fcnn_predictions_binary = (fcnn_predictions >= 0.5).astype(int)\n",
        "\n",
        "# Print anomalies for FCNN\n",
        "fcnn_anomalies_indices = y_test[fcnn_predictions_binary.flatten() != y_test].index\n",
        "\n",
        "\n",
        "# Compute accuracy for FCNN\n",
        "fcnn_accuracy = accuracy_score(y_test, fcnn_predictions_binary)\n",
        "\n",
        "\n",
        "# Make predictions for GRU\n",
        "gru_predictions = gru_model.predict(X_test_rnn)\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold of 0.5\n",
        "gru_predictions_binary = (gru_predictions >= 0.5).astype(int)\n",
        "\n",
        "# Print anomalies for GRU\n",
        "gru_anomalies_indices = y_test[gru_predictions_binary.flatten() != y_test].index\n",
        "\n",
        "\n",
        "# Compute accuracy for GRU\n",
        "gru_accuracy = accuracy_score(y_test, gru_predictions_binary)\n",
        "\n",
        "print(\"Anomalies detected by RNN:\", rnn_anomalies_indices)\n",
        "print(\"Anomalies detected by CNN:\", cnn_anomalies_indices)\n",
        "print(\"Anomalies detected by FCNN:\", fcnn_anomalies_indices)\n",
        "print(\"Anomalies detected by GRU:\", gru_anomalies_indices)\n",
        "\n",
        "print(\"RNN Accuracy:\", rnn_accuracy)\n",
        "print(\"CNN Accuracy:\", cnn_accuracy)\n",
        "print(\"FCNN Accuracy:\", fcnn_accuracy)\n",
        "print(\"GRU Accuracy:\", gru_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uZ0wLAzZEKH",
        "outputId": "357392ba-59c3-4561-cbd1-5c5a20ab080a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Anomalies detected by RNN: []\n",
            "Anomalies detected by CNN: Index([280, 39, 261, 244, 231, 237], dtype='int64')\n",
            "Anomalies detected by FCNN: Index([894], dtype='int64')\n",
            "Anomalies detected by GRU: Index([482], dtype='int64')\n",
            "RNN Accuracy: 1.0\n",
            "CNN Accuracy: 0.9698492462311558\n",
            "FCNN Accuracy: 0.9949748743718593\n",
            "GRU Accuracy: 0.9949748743718593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NWm9b7k8aI_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eM0pkxqi6eB",
        "outputId": "6a6dad13-6695-452c-b6a3-346ae0675fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}